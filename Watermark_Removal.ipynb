{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLSgfWt0JxaT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/data.zip # dataset used to train, pls change path as per instance\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "NTJMSoZLnE3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
        "%matplotlib inline\n",
        "def denorm(img_tensors): \n",
        "    return img_tensors * stats[1][0] + stats[0][0]\n",
        "def show_images(image): \n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid(denorm(image.detach()), nrow=1).permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "VQcLf-o9orgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path1 = \"/content/wm-nowm/train/no-watermark\"\n",
        "path2 = \"/content/wm-nowm/train/watermark\"\n",
        "def findCommonDeep(path1, path2):\n",
        "    return list(set.intersection(*(set(file for _, _, files in os.walk(path) for file in files) for path in (path1, path2))))\n",
        "\n",
        "common = findCommonDeep(path1, path2)"
      ],
      "metadata": {
        "id": "5zxahA8yiV43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common[0]"
      ],
      "metadata": {
        "id": "AIenGKiumU-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CreateDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, img_path, clean_img_path, len):\n",
        "    self.len = len\n",
        "    self.transforms = torchvision.transforms.Compose(\n",
        "            [\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize((512,512)),\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                      (0.5, 0.5, 0.5))\n",
        "            ]\n",
        "        )\n",
        "    self.img_path = img_path\n",
        "    self.clean_img_path = clean_img_path\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    watermarked_img = torchvision.io.read_image(self.img_path + \"/\" + common[index])\n",
        "    watermarked_img = self.transforms(watermarked_img)\n",
        "    clean_img = torchvision.io.read_image(self.clean_img_path + \"/\" + common[index])\n",
        "    clean_img = self.transforms(clean_img)\n",
        "    return watermarked_img, clean_img\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len"
      ],
      "metadata": {
        "id": "ZbVYW6_a3YOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UBlock(nn.Module):\n",
        "  def __init__(self, in_channels=3, out_channels=3):\n",
        "    super(UBlock, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(self.in_channels, 48, kernel_size = 3, stride = 1, padding=1), \n",
        "        nn.ReLU())\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(48, 48, kernel_size = 3, stride = 1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 1)\n",
        "    )\n",
        "    self.layer3 = nn.Sequential( \n",
        "        nn.Conv2d(48, 48, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 1))\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Conv2d(48, 48, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 1)\n",
        "    )\n",
        "    self.layer5 = nn.Sequential(\n",
        "        nn.Conv2d(48, 48, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 1)\n",
        "    )\n",
        "    self.layer6 = nn.Sequential(\n",
        "        nn.Conv2d(48, 48, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 1)\n",
        "    )\n",
        "    self.layer7 = nn.Sequential(\n",
        "        nn.Conv2d(48, 48, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 1)\n",
        "    )\n",
        "    self.g1 = nn.Sequential(\n",
        "        nn.Conv2d(48, 48, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(48, 48, kernel_size = 3, stride = 1)     \n",
        "    )\n",
        "    self.b1 = nn.Sequential(\n",
        "        nn.Conv2d(96, 96, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.g2 = nn.Sequential(\n",
        "        nn.Conv2d(96, 96, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(96, 96, kernel_size = 3, stride = 1)\n",
        "    )\n",
        "    self.b2 = nn.Sequential(\n",
        "        nn.Conv2d(144, 96, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.g3 = nn.Sequential(\n",
        "        nn.Conv2d(96, 96, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(96, 96, kernel_size = 3, stride = 1)\n",
        "    )\n",
        "    self.b3 = nn.Sequential(\n",
        "        nn.Conv2d(144, 96, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.g4 = nn.Sequential(\n",
        "        nn.Conv2d(96, 96, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(96, 96, kernel_size = 3, stride = 1)\n",
        "    )\n",
        "    self.b4 = nn.Sequential(\n",
        "        nn.Conv2d(144, 96, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.g5 = nn.Sequential(\n",
        "        nn.Conv2d(96, 96, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(96, 96, kernel_size = 3, stride = 1)\n",
        "    )\n",
        "    self.b5 = nn.Sequential(\n",
        "        nn.Conv2d(144, 96, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.g6 = nn.Sequential(\n",
        "        nn.Conv2d(96, 96, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(96, 96, kernel_size = 3, stride = 1)\n",
        "    )\n",
        "    self.b6 = nn.Sequential(\n",
        "        nn.Conv2d(99, 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layer_out = nn.Sequential(\n",
        "        nn.Conv2d(64, 32, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 3, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.LeakyReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    residual1 = x\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    residual2 = x\n",
        "    x = self.layer3(x)\n",
        "    residual3 = x\n",
        "    x = self.layer4(x)\n",
        "    residual4 = x\n",
        "    x = self.layer5(x)\n",
        "    residual5 = x\n",
        "    x = self.layer6(x)\n",
        "    residual6 = x\n",
        "    x = self.layer7(x)\n",
        "    x = self.g1(x)\n",
        "    x = self.b1(torch.cat((x, residual6),0))\n",
        "    x = self.g2(x)\n",
        "    x = self.b2(torch.cat((x, residual5),0))\n",
        "    x = self.g3(x)\n",
        "    x = self.b3(torch.cat((x, residual4),0))\n",
        "    x = self.g4(x)\n",
        "    x = self.b4(torch.cat((x, residual3),0))\n",
        "    x = self.g5(x)\n",
        "    x = self.b5(torch.cat((x, residual2),0))\n",
        "    x = self.g6(x)\n",
        "    x = self.b6(torch.cat((x, residual1),0))\n",
        "    x = self.layer_out(x)\n",
        "    return x "
      ],
      "metadata": {
        "id": "bMvpeyGLLcA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.block1 = UBlock()\n",
        "    self.block2 = UBlock()\n",
        "  \n",
        "  def forward(self, img):\n",
        "    out = self.block1(img)\n",
        "    print(out.shape)\n",
        "    out = self.block2(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "KQ4PRW_Ku061"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/wm-nowm/train/watermark\"\n",
        "clean_img_path = \"/content/wm-nowm/train/no-watermark\""
      ],
      "metadata": {
        "id": "EPVJAeq37nkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' "
      ],
      "metadata": {
        "id": "tx1g6lTq8pkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.L1Loss()\n",
        "model = Model()\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
        "T_max = 30\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)"
      ],
      "metadata": {
        "id": "EYhptrVtvnUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"/content/model (8).pth\")) # loading least loss model at time of submission of form "
      ],
      "metadata": {
        "id": "aVVgjxIZzDZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(watermarked_image, clean_image, loss_function, optimizer):\n",
        "  optimizer.zero_grad()\n",
        "  pred_img = model(watermarked_image) # getting predictions\n",
        "  loss = loss_function(pred_img, clean_image) # calculating the loss\n",
        "  loss.backward() # back propogating\n",
        "  optimizer.step()\n",
        "  return pred_img, loss.item()"
      ],
      "metadata": {
        "id": "bj3keTJ52429"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CreateDataset(img_path, clean_img_path, len(common))\n",
        "train_dataloader = DataLoader(dataset = train_dataset, batch_size=16, shuffle=True, pin_memory=True)"
      ],
      "metadata": {
        "id": "7eiTXJu57Z-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CreateDataset(img_path, clean_img_path, len(common))\n",
        "test_dataloader = DataLoader(dataset = test_dataset, batch_size=16, shuffle=True, pin_memory=True)"
      ],
      "metadata": {
        "id": "xraQOUUt8FbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(epochs, optimizer, loss_function):\n",
        "  losses = []\n",
        "  for epoch in range(epochs):\n",
        "      with torch.autograd.set_detect_anomaly(True):\n",
        "        for  i,(watermarked_img, clean_img) in enumerate(tqdm(train_dataloader)):\n",
        "          watermarked_img = watermarked_img.to(device)\n",
        "          clean_img = clean_img.to(device)\n",
        "          pred_img , train_loss = train(watermarked_img, clean_img, loss_function, optimizer)\n",
        "          losses.append(train_loss)\n",
        "      print(\"Epoch [{}/{}], train_loss: {:.4f}\".format(epoch+1, epochs, train_loss))\n",
        "  return losses"
      ],
      "metadata": {
        "id": "swA5KzYA8SHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(epochs, optimizer, loss_function):\n",
        "  losses = []\n",
        "  preds = []\n",
        "  actual = []\n",
        "  for epoch in range(epochs):\n",
        "    for i, (watermarked_img,clean_img) in enumerate(tqdm(test_dataloader)):\n",
        "          watermarked_img = watermarked_img.to(device)\n",
        "          clean_img = clean_img.to(device)\n",
        "          pred_img , test_loss = train(watermarked_img, clean_img, loss_function, optimizer)\n",
        "          losses.append(test_loss)\n",
        "          preds.append(pred_img)\n",
        "          actual.append(clean_img)\n",
        "    print(\"Epoch [{}/{}], val_loss: {:.4f}\".format(epoch+1, epochs, test_loss))\n",
        "  return losses, preds, actual"
      ],
      "metadata": {
        "id": "sl9dtlkD82C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit(epochs=100, optimizer=optimizer, loss_function=loss_function)"
      ],
      "metadata": {
        "id": "4N7ICztE_CCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(epochs=100, optimizer=optimizer, loss_function = loss_function)"
      ],
      "metadata": {
        "id": "rryRQisBOUjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of test images\n",
        "\n",
        "watermarked_img = torchvision.io.read_image(\"/content/PS2_test_image_7.jpg\")\n",
        "watermarked_img = transforms.ToPILImage()(watermarked_img)\n",
        "set_transforms = torchvision.transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((512,512)),\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                      (0.5, 0.5, 0.5))\n",
        "            ]\n",
        "        )\n",
        "watermarked_img = set_transforms(watermarked_img).to(device)\n",
        "pred = model(watermarked_img)\n",
        "show_images(pred.cpu())"
      ],
      "metadata": {
        "id": "MCnieDMyOdSs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}